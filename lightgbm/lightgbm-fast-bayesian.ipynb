{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import lightgbm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../output/lgbm_importances_bayesian.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lightgbm(df, num_folds, stratified = False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    \n",
    "    cat_cols = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "                'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "                'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', \n",
    "                'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "                'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "                'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', \n",
    "                'FLAG_DOCUMENT_18', 'CODE_GENDER', 'NAME_CONTRACT_TYPE',\n",
    "                'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'EMERGENCYSTATE_MODE',\n",
    "                'HOUSETYPE_MODE', 'FONDKAPREMONT_MODE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "                'NAME_HOUSING_TYPE', 'NAME_TYPE_SUITE', 'WALLSMATERIAL_MODE','WEEKDAY_APPR_PROCESS_START',\n",
    "                'NAME_INCOME_TYPE', 'OCCUPATION_TYPE', 'ORGANIZATION_TYPE', 'TARGET']\n",
    "    \n",
    "    included_cat_cols = [i for i in cat_cols if i in list(train_df.columns)]\n",
    "    included_cat_cols.remove('TARGET')\n",
    "\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df, cat_cols\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        dtrain = lightgbm.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                             label=train_df['TARGET'].iloc[train_idx], \n",
    "                             free_raw_data=False, silent=True,\n",
    "                             categorical_feature=included_cat_cols)\n",
    "        dvalid = lightgbm.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                             label=train_df['TARGET'].iloc[valid_idx], \n",
    "                             free_raw_data=False, silent=True,\n",
    "                             categorical_feature=included_cat_cols)\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt', # 'goss'\n",
    "            'nthread': 4,\n",
    "            'learning_rate': 0.02,  # 02,\n",
    "            'num_leaves': 20,\n",
    "            'colsample_bytree': 0.9497036,\n",
    "            'subsample': 0.8715623,\n",
    "            'subsample_freq': 1,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': 0.041545473,\n",
    "            'reg_lambda': 0.0735294,\n",
    "            'min_split_gain': 0.0222415,\n",
    "            'min_child_weight': 39.3259775, # 60\n",
    "            'seed': 0,\n",
    "            'verbose': -1,\n",
    "            'metric': 'auc',\n",
    "        }\n",
    "\n",
    "        clf = lightgbm.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds= 200,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(dvalid.label, oof_preds[valid_idx])))\n",
    "        del clf, dtrain, dvalid\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    sub_df = test_df[['SK_ID_CURR']].copy()\n",
    "    sub_df['TARGET'] = sub_preds\n",
    "    sub_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307511, 821), test shape: (48744, 821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.766728\tvalid_1's auc: 0.757309\n",
      "[200]\ttraining's auc: 0.78787\tvalid_1's auc: 0.773757\n",
      "[300]\ttraining's auc: 0.799993\tvalid_1's auc: 0.781098\n",
      "[400]\ttraining's auc: 0.808872\tvalid_1's auc: 0.785421\n",
      "[500]\ttraining's auc: 0.816299\tvalid_1's auc: 0.788178\n",
      "[600]\ttraining's auc: 0.822765\tvalid_1's auc: 0.789981\n",
      "[700]\ttraining's auc: 0.828782\tvalid_1's auc: 0.791092\n",
      "[800]\ttraining's auc: 0.834299\tvalid_1's auc: 0.791774\n",
      "[900]\ttraining's auc: 0.839302\tvalid_1's auc: 0.792357\n",
      "[1000]\ttraining's auc: 0.844084\tvalid_1's auc: 0.792801\n",
      "[1100]\ttraining's auc: 0.848575\tvalid_1's auc: 0.79303\n",
      "[1200]\ttraining's auc: 0.852885\tvalid_1's auc: 0.793346\n",
      "[1300]\ttraining's auc: 0.857021\tvalid_1's auc: 0.793601\n",
      "[1400]\ttraining's auc: 0.860971\tvalid_1's auc: 0.793618\n",
      "[1500]\ttraining's auc: 0.86483\tvalid_1's auc: 0.793725\n",
      "[1600]\ttraining's auc: 0.868429\tvalid_1's auc: 0.793831\n",
      "[1700]\ttraining's auc: 0.871913\tvalid_1's auc: 0.793863\n",
      "[1800]\ttraining's auc: 0.875353\tvalid_1's auc: 0.794101\n",
      "[1900]\ttraining's auc: 0.878806\tvalid_1's auc: 0.794178\n",
      "[2000]\ttraining's auc: 0.881948\tvalid_1's auc: 0.794264\n",
      "[2100]\ttraining's auc: 0.884925\tvalid_1's auc: 0.794134\n",
      "Early stopping, best iteration is:\n",
      "[1986]\ttraining's auc: 0.881504\tvalid_1's auc: 0.79431\n",
      "Fold  1 AUC : 0.794206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.766316\tvalid_1's auc: 0.755496\n",
      "[200]\ttraining's auc: 0.7876\tvalid_1's auc: 0.773108\n",
      "[300]\ttraining's auc: 0.799861\tvalid_1's auc: 0.780727\n",
      "[400]\ttraining's auc: 0.808658\tvalid_1's auc: 0.784931\n",
      "[500]\ttraining's auc: 0.816305\tvalid_1's auc: 0.787414\n",
      "[600]\ttraining's auc: 0.823067\tvalid_1's auc: 0.788998\n",
      "[700]\ttraining's auc: 0.829086\tvalid_1's auc: 0.790116\n",
      "[800]\ttraining's auc: 0.834441\tvalid_1's auc: 0.79096\n",
      "[900]\ttraining's auc: 0.839536\tvalid_1's auc: 0.79148\n",
      "[1000]\ttraining's auc: 0.844372\tvalid_1's auc: 0.791874\n",
      "[1100]\ttraining's auc: 0.84898\tvalid_1's auc: 0.792183\n",
      "[1200]\ttraining's auc: 0.853261\tvalid_1's auc: 0.792507\n",
      "[1300]\ttraining's auc: 0.857333\tvalid_1's auc: 0.792647\n",
      "[1400]\ttraining's auc: 0.861174\tvalid_1's auc: 0.792754\n",
      "[1500]\ttraining's auc: 0.864876\tvalid_1's auc: 0.792909\n",
      "[1600]\ttraining's auc: 0.868664\tvalid_1's auc: 0.793101\n",
      "[1700]\ttraining's auc: 0.872313\tvalid_1's auc: 0.793328\n",
      "[1800]\ttraining's auc: 0.875889\tvalid_1's auc: 0.793532\n",
      "[1900]\ttraining's auc: 0.87923\tvalid_1's auc: 0.793435\n",
      "[2000]\ttraining's auc: 0.882504\tvalid_1's auc: 0.793449\n",
      "Early stopping, best iteration is:\n",
      "[1801]\ttraining's auc: 0.875923\tvalid_1's auc: 0.793545\n",
      "Fold  2 AUC : 0.793539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.767505\tvalid_1's auc: 0.751078\n",
      "[200]\ttraining's auc: 0.789019\tvalid_1's auc: 0.76731\n",
      "[300]\ttraining's auc: 0.801143\tvalid_1's auc: 0.774596\n",
      "[400]\ttraining's auc: 0.810104\tvalid_1's auc: 0.778641\n",
      "[500]\ttraining's auc: 0.817434\tvalid_1's auc: 0.781102\n",
      "[600]\ttraining's auc: 0.824233\tvalid_1's auc: 0.782769\n",
      "[700]\ttraining's auc: 0.830115\tvalid_1's auc: 0.783805\n",
      "[800]\ttraining's auc: 0.835539\tvalid_1's auc: 0.784791\n",
      "[900]\ttraining's auc: 0.840447\tvalid_1's auc: 0.785347\n",
      "[1000]\ttraining's auc: 0.845096\tvalid_1's auc: 0.785972\n",
      "[1100]\ttraining's auc: 0.849547\tvalid_1's auc: 0.786487\n",
      "[1200]\ttraining's auc: 0.853834\tvalid_1's auc: 0.78673\n",
      "[1300]\ttraining's auc: 0.857829\tvalid_1's auc: 0.787129\n",
      "[1400]\ttraining's auc: 0.861824\tvalid_1's auc: 0.787227\n",
      "[1500]\ttraining's auc: 0.865698\tvalid_1's auc: 0.787373\n",
      "[1600]\ttraining's auc: 0.869477\tvalid_1's auc: 0.787583\n",
      "[1700]\ttraining's auc: 0.872992\tvalid_1's auc: 0.787699\n",
      "[1800]\ttraining's auc: 0.876461\tvalid_1's auc: 0.787888\n",
      "[1900]\ttraining's auc: 0.879743\tvalid_1's auc: 0.788042\n",
      "[2000]\ttraining's auc: 0.882919\tvalid_1's auc: 0.788142\n",
      "[2100]\ttraining's auc: 0.886119\tvalid_1's auc: 0.788171\n",
      "[2200]\ttraining's auc: 0.889127\tvalid_1's auc: 0.788049\n",
      "Early stopping, best iteration is:\n",
      "[2080]\ttraining's auc: 0.885573\tvalid_1's auc: 0.788216\n",
      "Fold  3 AUC : 0.788188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.767069\tvalid_1's auc: 0.756492\n",
      "[200]\ttraining's auc: 0.78885\tvalid_1's auc: 0.771613\n",
      "[300]\ttraining's auc: 0.8011\tvalid_1's auc: 0.778269\n",
      "[400]\ttraining's auc: 0.809985\tvalid_1's auc: 0.781967\n",
      "[500]\ttraining's auc: 0.817507\tvalid_1's auc: 0.784521\n",
      "[600]\ttraining's auc: 0.824069\tvalid_1's auc: 0.786139\n",
      "[700]\ttraining's auc: 0.829959\tvalid_1's auc: 0.787184\n",
      "[800]\ttraining's auc: 0.835436\tvalid_1's auc: 0.788008\n",
      "[900]\ttraining's auc: 0.840607\tvalid_1's auc: 0.788669\n",
      "[1000]\ttraining's auc: 0.845275\tvalid_1's auc: 0.789206\n",
      "[1100]\ttraining's auc: 0.849707\tvalid_1's auc: 0.789535\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    df = pd.read_csv('../data/processed_data_2.5.csv')\n",
    "    df = df.drop('Unnamed: 0', axis = 1)\n",
    "    \n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 5, stratified = False) \n",
    "        \n",
    "    return feat_importance\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"../predictions/lightgbm_pred_bayesian.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        feat_importance = main()\n",
    "        importance_df = feat_importance.groupby('feature').agg('mean').drop('fold', axis = 1).sort_values('importance')\n",
    "        importance_df.to_csv('../output/importance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
