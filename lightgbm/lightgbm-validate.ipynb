{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import lightgbm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../output/lgbm_importances_bayesian.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lightgbm(num_folds, stratified = False, corr_save = False, importance_save = False):\n",
    "    \n",
    "    train_df = pd.read_csv('../data/train_cv.csv')\n",
    "    test_df = pd.read_csv('../data/test_cv.csv')\n",
    "    \n",
    "    # Correlation csv processing\n",
    "    if corr_save == True:\n",
    "        target_corr = train_df.corr()['TARGET'].sort_values()\n",
    "        corr_df = pd.DataFrame()\n",
    "        corr_df['feature'] = target_corr.index\n",
    "        corr_df['corr'] = target_corr.values\n",
    "        corr_df = corr_df[corr_df['feature'] != 'feature']\n",
    "        corr_df.to_csv('../output/correlation_val.csv')\n",
    "        del target_corr, corr_df\n",
    "\n",
    "    # Create list of categorical columns\n",
    "    cat_cols = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "                'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "                'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', \n",
    "                'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "                'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "                'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', \n",
    "                'FLAG_DOCUMENT_18', 'CODE_GENDER', 'NAME_CONTRACT_TYPE',\n",
    "                'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'EMERGENCYSTATE_MODE',\n",
    "                'HOUSETYPE_MODE', 'FONDKAPREMONT_MODE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "                'NAME_HOUSING_TYPE', 'NAME_TYPE_SUITE', 'WALLSMATERIAL_MODE','WEEKDAY_APPR_PROCESS_START',\n",
    "                'NAME_INCOME_TYPE', 'OCCUPATION_TYPE', 'ORGANIZATION_TYPE', 'TARGET', 'FLAG_MOBIL_EMP_WORK_PHONE',\n",
    "                'FLAG_CAR_AND_REALTY', 'FLAG_GENDER_AND_CAR', 'FLAG_GENDER_AND_REALTY',\n",
    "                'FLAG_GENDER_AND_PHONE', 'FLAG_GENDER_AND_WORK_PHONE', 'FLAG_GENDER_AND_EMAIL',\n",
    "                'REGION_RATING_W_CAR', 'REGION_RATING_W_REALTY',\n",
    "                'REGION_RATING_W_EMP_PHONE', 'REGION_RATING_W_WORK_PHONE', 'REGION_RATING_W_PHONE', \n",
    "                'REGION_RATING_CITY_W_CAR', 'REGION_RATING_CITY_W_REALTY',\n",
    "                'REGION_RATING_CITY_W_EMP_PHONE', 'REGION_RATING_CITY_W_WORK_PHONE',\n",
    "                'REGION_RATING_CITY_W_PHONE', 'REGION_RATING_CITY_W_EMAIL', 'REGION_RATING_W_CITY_PROD', \n",
    "                'HOUR_APPR_PROCESS_START', 'FLAG_REG_CITY_NOT_LIVE_WORK']\n",
    "    \n",
    "    included_cat_cols = [i for i in cat_cols if i in list(train_df.columns)]\n",
    "    included_cat_cols.remove('TARGET')\n",
    "    \n",
    "    # Delete variables from memory \n",
    "    del cat_cols\n",
    "\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    # Initialise predictions and importance dataframes and epoch weights\n",
    "    feature_importance_df = pd.DataFrame()    \n",
    "    \n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        dtrain = lightgbm.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                             label=train_df['TARGET'].iloc[train_idx], \n",
    "                             free_raw_data=False, silent=True,\n",
    "                             categorical_feature=included_cat_cols)\n",
    "        dvalid = lightgbm.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                             label=train_df['TARGET'].iloc[valid_idx], \n",
    "                             free_raw_data=False, silent=True,\n",
    "                             categorical_feature=included_cat_cols)\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt', # 'goss'\n",
    "            'nthread': 4,\n",
    "            'learning_rate': 0.02,  # 02,\n",
    "            'num_leaves': 20,\n",
    "            'colsample_bytree': 0.9497036,\n",
    "            'subsample': 0.8715623,\n",
    "            'subsample_freq': 1,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': 0.041545473,\n",
    "            'reg_lambda': 0.0735294,\n",
    "            'min_split_gain': 0.0222415,\n",
    "            'min_child_weight': 39.3259775, # 60\n",
    "            'seed': 0,\n",
    "            'verbose': -1,\n",
    "            'metric': 'auc',\n",
    "        }\n",
    "\n",
    "        clf = lightgbm.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds= 200,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "\n",
    "        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n",
    "\n",
    "        del clf, dtrain, dvalid\n",
    "            \n",
    "    target = np.genfromtxt('../data/target_cv.csv', delimiter=',')\n",
    "    cv_auc = roc_auc_score(target, sub_preds)\n",
    "    print('AUC on validation set: {}'.format(cv_auc))\n",
    "    \n",
    "    # Save feature importance df as csv\n",
    "    if importance_save == True:\n",
    "        feature_importance_df = feature_importance_df.groupby('feature').agg('mean').drop('fold', axis = 1).sort_values('importance')\n",
    "        feature_importance_df.to_csv('../output/importance_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (246008, 968), test shape: (61503, 968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.771664\tvalid_1's auc: 0.75885\n",
      "[200]\ttraining's auc: 0.793536\tvalid_1's auc: 0.77372\n",
      "[300]\ttraining's auc: 0.806165\tvalid_1's auc: 0.780194\n",
      "[400]\ttraining's auc: 0.815912\tvalid_1's auc: 0.783759\n",
      "[500]\ttraining's auc: 0.824394\tvalid_1's auc: 0.78609\n",
      "[600]\ttraining's auc: 0.831846\tvalid_1's auc: 0.787767\n",
      "[700]\ttraining's auc: 0.83855\tvalid_1's auc: 0.788722\n",
      "[800]\ttraining's auc: 0.844615\tvalid_1's auc: 0.789556\n",
      "[900]\ttraining's auc: 0.850296\tvalid_1's auc: 0.789829\n",
      "[1000]\ttraining's auc: 0.855847\tvalid_1's auc: 0.790267\n",
      "[1100]\ttraining's auc: 0.861026\tvalid_1's auc: 0.790787\n",
      "[1200]\ttraining's auc: 0.865993\tvalid_1's auc: 0.791014\n",
      "[1300]\ttraining's auc: 0.870832\tvalid_1's auc: 0.791211\n",
      "[1400]\ttraining's auc: 0.875321\tvalid_1's auc: 0.791369\n",
      "[1500]\ttraining's auc: 0.879684\tvalid_1's auc: 0.79152\n",
      "[1600]\ttraining's auc: 0.883784\tvalid_1's auc: 0.791652\n",
      "[1700]\ttraining's auc: 0.887801\tvalid_1's auc: 0.791795\n",
      "[1800]\ttraining's auc: 0.891808\tvalid_1's auc: 0.791813\n",
      "[1900]\ttraining's auc: 0.895747\tvalid_1's auc: 0.791853\n",
      "[2000]\ttraining's auc: 0.899327\tvalid_1's auc: 0.791827\n",
      "[2100]\ttraining's auc: 0.902823\tvalid_1's auc: 0.791844\n",
      "Early stopping, best iteration is:\n",
      "[1959]\ttraining's auc: 0.897885\tvalid_1's auc: 0.791933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.771157\tvalid_1's auc: 0.759719\n",
      "[200]\ttraining's auc: 0.79318\tvalid_1's auc: 0.775017\n",
      "[300]\ttraining's auc: 0.805996\tvalid_1's auc: 0.781578\n",
      "[400]\ttraining's auc: 0.815974\tvalid_1's auc: 0.784948\n",
      "[500]\ttraining's auc: 0.824446\tvalid_1's auc: 0.786899\n",
      "[600]\ttraining's auc: 0.832052\tvalid_1's auc: 0.787999\n",
      "[700]\ttraining's auc: 0.838904\tvalid_1's auc: 0.788967\n",
      "[800]\ttraining's auc: 0.845134\tvalid_1's auc: 0.789589\n",
      "[900]\ttraining's auc: 0.850773\tvalid_1's auc: 0.789946\n",
      "[1000]\ttraining's auc: 0.85619\tvalid_1's auc: 0.790331\n",
      "[1100]\ttraining's auc: 0.861537\tvalid_1's auc: 0.790659\n",
      "[1200]\ttraining's auc: 0.866369\tvalid_1's auc: 0.790602\n",
      "[1300]\ttraining's auc: 0.871103\tvalid_1's auc: 0.790698\n",
      "[1400]\ttraining's auc: 0.875623\tvalid_1's auc: 0.790708\n",
      "[1500]\ttraining's auc: 0.879967\tvalid_1's auc: 0.790783\n",
      "[1600]\ttraining's auc: 0.884055\tvalid_1's auc: 0.790821\n",
      "[1700]\ttraining's auc: 0.888041\tvalid_1's auc: 0.790834\n",
      "[1800]\ttraining's auc: 0.891928\tvalid_1's auc: 0.790956\n",
      "[1900]\ttraining's auc: 0.895575\tvalid_1's auc: 0.790898\n",
      "Early stopping, best iteration is:\n",
      "[1781]\ttraining's auc: 0.891106\tvalid_1's auc: 0.791004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.77171\tvalid_1's auc: 0.759328\n",
      "[200]\ttraining's auc: 0.793245\tvalid_1's auc: 0.773459\n",
      "[300]\ttraining's auc: 0.806241\tvalid_1's auc: 0.779807\n",
      "[400]\ttraining's auc: 0.816284\tvalid_1's auc: 0.782935\n",
      "[500]\ttraining's auc: 0.824765\tvalid_1's auc: 0.784971\n",
      "[600]\ttraining's auc: 0.832381\tvalid_1's auc: 0.786175\n",
      "[700]\ttraining's auc: 0.839253\tvalid_1's auc: 0.787174\n",
      "[800]\ttraining's auc: 0.845634\tvalid_1's auc: 0.78786\n",
      "[900]\ttraining's auc: 0.851408\tvalid_1's auc: 0.788436\n",
      "[1000]\ttraining's auc: 0.856798\tvalid_1's auc: 0.788683\n",
      "[1100]\ttraining's auc: 0.86215\tvalid_1's auc: 0.788904\n",
      "[1200]\ttraining's auc: 0.867049\tvalid_1's auc: 0.788983\n",
      "[1300]\ttraining's auc: 0.87188\tvalid_1's auc: 0.78928\n",
      "[1400]\ttraining's auc: 0.876461\tvalid_1's auc: 0.78934\n",
      "[1500]\ttraining's auc: 0.88071\tvalid_1's auc: 0.789427\n",
      "[1600]\ttraining's auc: 0.884811\tvalid_1's auc: 0.789117\n",
      "[1700]\ttraining's auc: 0.888792\tvalid_1's auc: 0.789067\n",
      "Early stopping, best iteration is:\n",
      "[1500]\ttraining's auc: 0.88071\tvalid_1's auc: 0.789427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.771199\tvalid_1's auc: 0.760083\n",
      "[200]\ttraining's auc: 0.792698\tvalid_1's auc: 0.775226\n",
      "[300]\ttraining's auc: 0.805616\tvalid_1's auc: 0.781909\n",
      "[400]\ttraining's auc: 0.815576\tvalid_1's auc: 0.785777\n",
      "[500]\ttraining's auc: 0.824181\tvalid_1's auc: 0.787972\n",
      "[600]\ttraining's auc: 0.831771\tvalid_1's auc: 0.789273\n",
      "[700]\ttraining's auc: 0.83846\tvalid_1's auc: 0.790191\n",
      "[800]\ttraining's auc: 0.844435\tvalid_1's auc: 0.790922\n",
      "[900]\ttraining's auc: 0.850517\tvalid_1's auc: 0.791334\n",
      "[1000]\ttraining's auc: 0.856105\tvalid_1's auc: 0.791652\n",
      "[1100]\ttraining's auc: 0.861364\tvalid_1's auc: 0.792021\n",
      "[1200]\ttraining's auc: 0.866327\tvalid_1's auc: 0.792242\n",
      "[1300]\ttraining's auc: 0.87106\tvalid_1's auc: 0.792506\n",
      "[1400]\ttraining's auc: 0.875452\tvalid_1's auc: 0.79261\n",
      "[1500]\ttraining's auc: 0.87977\tvalid_1's auc: 0.792825\n",
      "[1600]\ttraining's auc: 0.884\tvalid_1's auc: 0.792832\n",
      "[1700]\ttraining's auc: 0.888166\tvalid_1's auc: 0.792779\n",
      "[1800]\ttraining's auc: 0.891959\tvalid_1's auc: 0.792764\n",
      "Early stopping, best iteration is:\n",
      "[1648]\ttraining's auc: 0.886\tvalid_1's auc: 0.792943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.77203\tvalid_1's auc: 0.754441\n",
      "[200]\ttraining's auc: 0.793917\tvalid_1's auc: 0.770324\n",
      "[300]\ttraining's auc: 0.806708\tvalid_1's auc: 0.776604\n",
      "[400]\ttraining's auc: 0.816707\tvalid_1's auc: 0.780463\n",
      "[500]\ttraining's auc: 0.825315\tvalid_1's auc: 0.782628\n",
      "[600]\ttraining's auc: 0.832643\tvalid_1's auc: 0.783747\n",
      "[700]\ttraining's auc: 0.83941\tvalid_1's auc: 0.784675\n",
      "[800]\ttraining's auc: 0.845351\tvalid_1's auc: 0.785296\n",
      "[900]\ttraining's auc: 0.851165\tvalid_1's auc: 0.785529\n",
      "[1000]\ttraining's auc: 0.856535\tvalid_1's auc: 0.785736\n",
      "[1100]\ttraining's auc: 0.861698\tvalid_1's auc: 0.786135\n",
      "[1200]\ttraining's auc: 0.866701\tvalid_1's auc: 0.786558\n",
      "[1300]\ttraining's auc: 0.871286\tvalid_1's auc: 0.786807\n",
      "[1400]\ttraining's auc: 0.875792\tvalid_1's auc: 0.7868\n",
      "[1500]\ttraining's auc: 0.880224\tvalid_1's auc: 0.786805\n",
      "[1600]\ttraining's auc: 0.884207\tvalid_1's auc: 0.786977\n",
      "[1700]\ttraining's auc: 0.888274\tvalid_1's auc: 0.786928\n",
      "[1800]\ttraining's auc: 0.892169\tvalid_1's auc: 0.787114\n",
      "[1900]\ttraining's auc: 0.895922\tvalid_1's auc: 0.787092\n",
      "[2000]\ttraining's auc: 0.899516\tvalid_1's auc: 0.786997\n",
      "Early stopping, best iteration is:\n",
      "[1845]\ttraining's auc: 0.893868\tvalid_1's auc: 0.787154\n",
      "AUC on validation set: 0.7973189588195151\n",
      "Run LightGBM with kfold - done in 3210s\n",
      "Full model run - done in 3210s\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "        \n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feature_importance_df = kfold_lightgbm(num_folds=5,\n",
    "                                               stratified=False,\n",
    "                                               corr_save=False,\n",
    "                                               importance_save=False) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with timer(\"Full model run\"):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
