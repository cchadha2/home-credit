{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_and_test():\n",
    "    \n",
    "    application_train = pd.read_csv('../data/application_train.csv')\n",
    "    application_test = pd.read_csv('../data/application_test.csv')\n",
    "    \n",
    "    application_train = application_train.sort_values(by = 'SK_ID_CURR')\n",
    "    application_test = application_test.sort_values(by = 'SK_ID_CURR')\n",
    "    df = application_train.append(application_test).reset_index()\n",
    "\n",
    "    df['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "    df['CODE_GENDER'].replace({'XNA': np.nan}, inplace = True)\n",
    "    df['ORGANIZATION_TYPE'].replace({'XNA': np.nan}, inplace = True)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    useless_features = ['FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', \n",
    "                        'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_19', \n",
    "                        'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n",
    "    \n",
    "    df = df.drop(useless_features, axis = 1)\n",
    "    \n",
    "    docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "    live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n",
    "    \n",
    "    inc_by_org = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "\n",
    "    df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    df['NEW_DOC_IND_AVG'] = df[docs].mean(axis=1)\n",
    "    df['NEW_DOC_IND_STD'] = df[docs].std(axis=1)\n",
    "    df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n",
    "    df['NEW_LIVE_IND_STD'] = df[live].std(axis=1)\n",
    "    df['NEW_LIVE_IND_KURT'] = df[live].kurtosis(axis=1)\n",
    "    df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
    "    df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(inc_by_org)\n",
    "    df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n",
    "    df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n",
    "    df['NEW_CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    df['NEW_CAR_TO_EMPLOY_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "    df['NEW_PHONE_TO_EMPLOY_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_AMT_ANNUITY_RATIO'] = df['NEW_EXT_SOURCES_MEAN']/df['AMT_ANNUITY']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_AMT_CREDIT_RATIO'] = df['NEW_EXT_SOURCES_MEAN']/df['AMT_CREDIT']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_AMT_GOODS_PRICE_RATIO'] = df['NEW_EXT_SOURCES_MEAN']/df['AMT_GOODS_PRICE']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_AMT_INCOME_TOTAL_PROD'] = df['NEW_EXT_SOURCES_MEAN']*df['AMT_INCOME_TOTAL']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_DAYS_BIRTH_PROD'] = df['NEW_EXT_SOURCES_MEAN']*df['DAYS_BIRTH']\n",
    "#     df['NEW_EXT_SOURCES_MEAN_DAYS_EMPLOYED_PROD'] = df['NEW_EXT_SOURCES_MEAN']*df['DAYS_EMPLOYED']\n",
    "#     df['DAYS_REGISTRATION_ID'] = df['DAYS_REGISTRATION']*df['DAYS_ID_PUBLISH']\n",
    "#     df['EXT_SOURCES_PAYMENT_RATE'] = df['NEW_EXT_SOURCES_MEAN']*df['PAYMENT_RATE']\n",
    "#     df['AGE_TO_CAR_AGE_RATIO'] = df['DAYS_BIRTH']/df['OWN_CAR_AGE']\n",
    "#     df['AMT_REQ'] = (df['AMT_REQ_CREDIT_BUREAU_HOUR'] + df['AMT_REQ_CREDIT_BUREAU_DAY'] + \n",
    "#                      df['AMT_REQ_CREDIT_BUREAU_WEEK'] + df['AMT_REQ_CREDIT_BUREAU_MON'] + \n",
    "#                      df['AMT_REQ_CREDIT_BUREAU_QRT'] + df['AMT_REQ_CREDIT_BUREAU_YEAR'])\n",
    "#     df['CREDIT_PER_CHILD'] = df['AMT_CREDIT']/(1 + df['CNT_CHILDREN'])\n",
    "#     df['ANNUITY_PER_CHILD'] = df['AMT_ANNUITY']/(1 + df['CNT_CHILDREN'])\n",
    "#     df['GOODS_PER_CHILD'] = df['AMT_GOODS_PRICE']/(1 + df['CNT_CHILDREN'])\n",
    "#     df['CREDIT_PER_FAMILY_MEMBER'] = df['AMT_CREDIT']/df['CNT_FAM_MEMBERS']\n",
    "#     df['ANNUITY_PER_FAMILY_MEMBER'] = df['AMT_ANNUITY']/df['CNT_FAM_MEMBERS']\n",
    "#     df['GOODS_PER_FAMILY_MEMBER'] = df['AMT_GOODS_PRICE']/df['CNT_FAM_MEMBERS']\n",
    "#     df['FAM_SIZE_PER_POPULATION'] = df['CNT_FAM_MEMBERS']/df['REGION_POPULATION_RELATIVE']\n",
    "#     df['CHILDREN_PER_POPULATION'] = df['CNT_CHILDREN']/df['REGION_POPULATION_RELATIVE']\n",
    "\n",
    "    \n",
    "#     accom_avg_list = ['APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG',\n",
    "#                       'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG',\n",
    "#                       'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
    "#                       'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG']\n",
    "#     accom_mode_list = ['APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n",
    "#                       'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE',\n",
    "#                       'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE',\n",
    "#                       'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE',\n",
    "#                       'TOTALAREA_MODE']\n",
    "#     accom_medi_list = ['APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "#                       'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI',\n",
    "#                       'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI',\n",
    "#                       'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI']\n",
    "    \n",
    "#     df['ACCOM_SCORE_AVG'] = df[accom_avg_list].mean(axis=1)\n",
    "#     df['ACCOM_SCORE_MODE'] = df[accom_mode_list].mean(axis=1)\n",
    "#     df['ACCOM_SCORE_MEDI'] = df[accom_medi_list].mean(axis=1)\n",
    "#     df['DEF_AVE_CNT_SOCIAL_CIRCLE'] = df[['DEF_30_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']].mean(axis=1)\n",
    "#     df['OBS_AVE_CNT_SOCIAL_CIRCLE'] = df[['OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE']].mean(axis=1)\n",
    "#     df['30_CNT_SOCIAL_CIRCLE_RATIO'] = df['DEF_30_CNT_SOCIAL_CIRCLE']/df['OBS_30_CNT_SOCIAL_CIRCLE']\n",
    "#     df['60_CNT_SOCIAL_CIRCLE_RATIO'] = df['DEF_60_CNT_SOCIAL_CIRCLE']/df['OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "    \n",
    "    # Feature interactions\n",
    "    df['EXT_SOURCE_1_1'] = df['EXT_SOURCE_1']**2\n",
    "    df['EXT_SOURCE_1_2'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']\n",
    "    df['EXT_SOURCE_1_3'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCE_1_DAYS_BIRTH'] = df['EXT_SOURCE_1'] * df['DAYS_BIRTH']\n",
    "    df['EXT_SOURCE_2_2'] = df['EXT_SOURCE_2']**2\n",
    "    df['EXT_SOURCE_2_3'] = df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCE_2_DAYS_BIRTH'] = df['EXT_SOURCE_2'] * df['DAYS_BIRTH']\n",
    "    df['EXT_SOURCE_3_3'] = df['EXT_SOURCE_3']**2\n",
    "    df['EXT_SOURCE_3_DAYS_BIRTH'] = df['EXT_SOURCE_3'] * df['DAYS_BIRTH']\n",
    "    df['DAYS_BIRTH_DAYS_BIRTH'] = df['DAYS_BIRTH']**2\n",
    "    df['DAYS_EMPLOYED_DAYS_BIRTH'] = df['DAYS_EMPLOYED'] * df['DAYS_BIRTH']\n",
    "    df['DAYS_EMPLOYED_DAYS_EMPLOYED'] = df['DAYS_EMPLOYED']**2\n",
    "    df['AMT_CREDIT_AMT_ANNUITY'] = df['AMT_CREDIT'] * df['AMT_ANNUITY']\n",
    "    df['AMT_CREDIT_AMT_CREDIT'] = df['AMT_CREDIT']**2\n",
    "    df['AMT_ANNUITY_AMT_ANNUITY'] = df['AMT_ANNUITY']**2\n",
    "    \n",
    "    categorical_features = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "                            'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "                            'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', \n",
    "                            'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "                            'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "                            'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', \n",
    "                            'FLAG_DOCUMENT_18', 'CODE_GENDER', 'NAME_CONTRACT_TYPE',\n",
    "                            'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'EMERGENCYSTATE_MODE',\n",
    "                            'HOUSETYPE_MODE', 'FONDKAPREMONT_MODE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "                            'NAME_HOUSING_TYPE', 'NAME_TYPE_SUITE', 'WALLSMATERIAL_MODE','WEEKDAY_APPR_PROCESS_START',\n",
    "                            'HOUR_APPR_PROCESS_START', 'NAME_INCOME_TYPE', 'OCCUPATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        df[feature], uniques = pd.factorize(df[feature]) \n",
    "    \n",
    "    df = df.drop('index', axis=1)\n",
    "    \n",
    "    del application_train\n",
    "    del application_test\n",
    "    del categorical_features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(df):\n",
    "    \n",
    "    bureau = pd.read_csv('../data/bureau.csv')\n",
    "    bureau_balance = pd.read_csv('../data/bureau_balance.csv')\n",
    "    \n",
    "    previous_loans = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loans'})\n",
    "    df = df.merge(previous_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['previous_loans'] = df['previous_loans'].fillna(0)\n",
    "    \n",
    "    closed_loans = bureau[bureau['CREDIT_ACTIVE'] == 'Closed']\n",
    "    closed_loans = closed_loans.groupby('SK_ID_CURR', as_index=False)['CREDIT_ACTIVE'].count().rename(columns = {'CREDIT_ACTIVE': 'closed_loans'})\n",
    "    df = df.merge(closed_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['closed_loans'] = df['closed_loans'].fillna(0)\n",
    "    active_loans = bureau[bureau['CREDIT_ACTIVE'] == 'Active']\n",
    "    active_loans = active_loans.groupby('SK_ID_CURR', as_index=False)['CREDIT_ACTIVE'].count().rename(columns = {'CREDIT_ACTIVE': 'active_loans'})\n",
    "    df = df.merge(active_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['active_loans'] = df['active_loans'].fillna(0)\n",
    "        \n",
    "    bureau, bureau_cat_cols = one_hot_encoder(bureau)\n",
    "    bureau_balance, bureau_balance_cat_cols = one_hot_encoder(bureau_balance)\n",
    "    \n",
    "#     bureau['AMT_CREDIT_DEBT_PERC'] = bureau['AMT_CREDIT_SUM_DEBT']/bureau['AMT_CREDIT_SUM']\n",
    "#     bureau['AMT_CREDIT_LIMIT_PERC'] = bureau['AMT_CREDIT_SUM_LIMIT']/bureau['AMT_CREDIT_SUM']\n",
    "#     bureau['AMT_CREDIT_OVERDUE_PERC'] = bureau['AMT_CREDIT_SUM_OVERDUE']/bureau['AMT_CREDIT_SUM']\n",
    "#     bureau['AMT_CREDIT_MAX_OVERDUE_PERC'] = bureau['AMT_CREDIT_MAX_OVERDUE']/bureau['AMT_CREDIT_SUM']\n",
    "#     bureau['AMT_CREDIT_OVERDUE_CNT_CREDIT_PROLONG'] = bureau['AMT_CREDIT_SUM_OVERDUE']*bureau['CNT_CREDIT_PROLONG']\n",
    "#     bureau['DAYS_CREDIT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_UPDATE']\n",
    "#     bureau['ANNUITY_CREDIT_RATE'] = bureau['AMT_ANNUITY']/bureau['AMT_CREDIT_SUM']\n",
    "#     bureau['ANNUITY_DEBT_RATE'] = bureau['AMT_ANNUITY']/bureau['AMT_CREDIT_SUM_DEBT']\n",
    "#     bureau['ANNUITY_LIMIT_RATE'] = bureau['AMT_ANNUITY']/bureau['AMT_CREDIT_SUM_LIMIT']\n",
    "#     bureau['ANNUITY_OVERDUE_RATE'] = bureau['AMT_ANNUITY']/bureau['AMT_CREDIT_SUM_OVERDUE']\n",
    "#     bureau['ANNUITY_MAX_OVERDUE_RATE'] = bureau['AMT_ANNUITY']/bureau['AMT_CREDIT_MAX_OVERDUE']\n",
    "\n",
    "    bureau_aggregations = {'DAYS_CREDIT':['min', 'max', 'mean', 'var'],\n",
    "                           'CREDIT_DAY_OVERDUE':['max', 'mean'],\n",
    "                           'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "                           'DAYS_ENDDATE_FACT': ['mean'],\n",
    "                           'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "                           'CNT_CREDIT_PROLONG': ['count', 'sum'],\n",
    "                           'AMT_CREDIT_SUM': ['min', 'max', 'mean'],\n",
    "                           'AMT_CREDIT_SUM_DEBT': ['min', 'max', 'mean'],\n",
    "                           'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean'],\n",
    "                           'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "                           'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean'],\n",
    "                           'AMT_ANNUITY': ['max', 'mean'],\n",
    "                           'MONTHS_BALANCE_MIN': ['min'],\n",
    "                           'MONTHS_BALANCE_MAX': ['max'],\n",
    "                           'MONTHS_BALANCE_SIZE': ['mean', 'sum']}#,\n",
    "#                            'AMT_CREDIT_DEBT_PERC': ['mean', 'min', 'max'],\n",
    "#                            'AMT_CREDIT_LIMIT_PERC': ['mean', 'min', 'max'],\n",
    "#                            'AMT_CREDIT_OVERDUE_PERC': ['mean', 'min', 'max'],\n",
    "#                            'AMT_CREDIT_MAX_OVERDUE_PERC': ['mean', 'min', 'max'],\n",
    "#                            'AMT_CREDIT_OVERDUE_CNT_CREDIT_PROLONG': ['mean', 'sum'],\n",
    "#                            'DAYS_CREDIT_DIFF': ['mean', 'min', 'max'],\n",
    "#                            'ANNUITY_CREDIT_RATE': ['mean', 'min', 'max', 'sum', 'var'],\n",
    "#                            'ANNUITY_DEBT_RATE': ['mean'],\n",
    "#                            'ANNUITY_LIMIT_RATE': ['mean'],\n",
    "#                            'ANNUITY_OVERDUE_RATE': ['mean'],\n",
    "#                            'ANNUITY_MAX_OVERDUE_RATE': ['mean']}\n",
    "\n",
    "    bureau_balance_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    \n",
    "    for col in bureau_cat_cols:\n",
    "        bureau_aggregations[col] = ['mean']\n",
    "    for col in bureau_balance_cat_cols:\n",
    "        bureau_balance_aggregations[col] = ['mean']\n",
    "        \n",
    "    bureau_balance_aggregations = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_aggregations)\n",
    "    bureau_balance_aggregations.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bureau_balance_aggregations.columns.tolist()])\n",
    "    bureau = bureau.join(bureau_balance_aggregations, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "        \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg(bureau_aggregations)\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    \n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(bureau_aggregations)\n",
    "    cols = active_agg.columns.tolist()\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    \n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(bureau_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    for e in cols:\n",
    "        bureau_agg['NEW_RATIO_BURO_' + e[0] + \"_\" + e[1].upper()] = bureau_agg['ACTIVE_' + e[0] + \"_\" + e[1].upper()] / bureau_agg['CLOSED_' + e[0] + \"_\" + e[1].upper()]\n",
    "    \n",
    "    df = df.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "            \n",
    "    del bureau\n",
    "    del bureau_balance\n",
    "    del bureau_balance_aggregations\n",
    "    del bureau_agg\n",
    "    del previous_loans\n",
    "    del closed_loans\n",
    "    del active_loans\n",
    "    del closed\n",
    "    del closed_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_balance(df):\n",
    "    \n",
    "    credit_card_balance = pd.read_csv('../data/credit_card_balance.csv')\n",
    "    \n",
    "    current_loan_status = credit_card_balance[['SK_ID_CURR', 'SK_ID_PREV', 'NAME_CONTRACT_STATUS']].sort_values(by = ['SK_ID_CURR', 'NAME_CONTRACT_STATUS']).drop_duplicates()\n",
    "    current_loan_status = current_loan_status[current_loan_status['NAME_CONTRACT_STATUS'].isin(['Active', 'Completed'])]\n",
    "    \n",
    "    prev_credit_completed = current_loan_status[current_loan_status['NAME_CONTRACT_STATUS'] == 'Completed']\n",
    "    prev_credit_completed = pd.get_dummies(prev_credit_completed)\n",
    "    del prev_credit_completed['SK_ID_PREV']\n",
    "    prev_credit_completed = prev_credit_completed.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Completed'].count()\n",
    "    df = df.merge(prev_credit_completed, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Completed'] = df['NAME_CONTRACT_STATUS_Completed'].fillna(0)\n",
    "    \n",
    "    prev_credit_active = current_loan_status.drop_duplicates(subset = ['SK_ID_CURR', 'SK_ID_PREV'], keep = False)\n",
    "    prev_credit_active = prev_credit_active[prev_credit_active['NAME_CONTRACT_STATUS'] == 'Active']\n",
    "    prev_credit_active = pd.get_dummies(prev_credit_active)\n",
    "    del prev_credit_active['SK_ID_PREV']\n",
    "    prev_credit_active = prev_credit_active.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Active'].count()\n",
    "    df = df.merge(prev_credit_active, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Active'] = df['NAME_CONTRACT_STATUS_Active'].fillna(0)\n",
    "        \n",
    "    credit_card_balance.drop(columns = ['NAME_CONTRACT_STATUS', 'SK_ID_PREV'], inplace = True)\n",
    "    \n",
    "    cc_agg = credit_card_balance.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    cc_agg['CC_COUNT'] = credit_card_balance.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    df = df.merge(cc_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['CC_COUNT'] = df['CC_COUNT'].fillna(0)\n",
    "    \n",
    "    del credit_card_balance\n",
    "    del current_loan_status\n",
    "    del prev_credit_completed\n",
    "    del prev_credit_active\n",
    "    del cc_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments(df):\n",
    "    \n",
    "    ins = pd.read_csv('../data/installments_payments.csv')\n",
    "\n",
    "    ins['INSTALLMENTS_DAY_DIFF'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['INSTALLMENTS_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    # Feature interactions\n",
    "    ins['INSTALLMENTS_DIFF_INSTALLMENTS_DAY_DIFF'] = ins['INSTALLMENTS_DIFF'] * ins['INSTALLMENTS_DAY_DIFF']\n",
    "    ins['INSTALLMENTS_DIFF_INSTALLMENTS_DIFF'] = ins['INSTALLMENTS_DIFF']**2\n",
    "    ins['INSTALLMENTS_DAY_DIFF_INSTALLMENTS_DAY_DIFF'] = ins['INSTALLMENTS_DAY_DIFF']**2\n",
    "    \n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum'], \n",
    "        'INSTALLMENTS_DAY_DIFF': ['max', 'mean', 'sum', 'var'], \n",
    "        'INSTALLMENTS_DIFF': ['max', 'mean', 'sum', 'var'], \n",
    "        'INSTALLMENTS_DIFF_INSTALLMENTS_DAY_DIFF': ['max', 'mean', 'sum', 'var'], \n",
    "        'INSTALLMENTS_DIFF_INSTALLMENTS_DIFF': ['max', 'mean', 'sum', 'var'], \n",
    "        'INSTALLMENTS_DAY_DIFF_INSTALLMENTS_DAY_DIFF': ['max', 'mean', 'sum', 'var']\n",
    "    }\n",
    "    \n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    df = df.merge(ins_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del ins\n",
    "    del ins_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(df):\n",
    "    \n",
    "    POS_CASH_balance = pd.read_csv('../data/POS_CASH_balance.csv')\n",
    "\n",
    "    current_POS_status = POS_CASH_balance[['SK_ID_CURR', 'SK_ID_PREV', 'NAME_CONTRACT_STATUS']].sort_values(by = ['SK_ID_CURR', 'NAME_CONTRACT_STATUS']).drop_duplicates()\n",
    "    current_POS_status = current_POS_status[current_POS_status['NAME_CONTRACT_STATUS'].isin(['Active', 'Completed'])]\n",
    "\n",
    "    prev_POS_completed = current_POS_status[current_POS_status['NAME_CONTRACT_STATUS'] == 'Completed']\n",
    "    prev_POS_completed = pd.get_dummies(prev_POS_completed)\n",
    "    del prev_POS_completed['SK_ID_PREV']\n",
    "    prev_POS_completed = prev_POS_completed.rename(columns = {'NAME_CONTRACT_STATUS_Completed': 'NAME_CONTRACT_STATUS_Completed_POS'})\n",
    "    prev_POS_completed = prev_POS_completed.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Completed_POS'].count()\n",
    "    df = df.merge(prev_POS_completed, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Completed_POS'] = df['NAME_CONTRACT_STATUS_Completed_POS'].fillna(0)\n",
    "\n",
    "    prev_POS_active = current_POS_status.drop_duplicates(subset = ['SK_ID_CURR', 'SK_ID_PREV'], keep = False)\n",
    "    prev_POS_active = prev_POS_active[prev_POS_active['NAME_CONTRACT_STATUS'] == 'Active']\n",
    "    prev_POS_active = pd.get_dummies(prev_POS_active)\n",
    "    del prev_POS_active['SK_ID_PREV']\n",
    "    prev_POS_active = prev_POS_active.rename(columns = {'NAME_CONTRACT_STATUS_Active': 'NAME_CONTRACT_STATUS_Active_POS'})\n",
    "    prev_POS_active = prev_POS_active.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Active_POS'].count()\n",
    "    df = df.merge(prev_POS_active, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Active_POS'] = df['NAME_CONTRACT_STATUS_Active_POS'].fillna(0)\n",
    "    \n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean'], \n",
    "        'CNT_INSTALMENT': ['min', 'max', 'mean'],\n",
    "        'CNT_INSTALMENT_FUTURE': ['min', 'max', 'mean']\n",
    "    }\n",
    "\n",
    "    POS_CASH_balance.drop(columns = ['NAME_CONTRACT_STATUS', 'SK_ID_PREV'], inplace = True) \n",
    "    POS_CASH_balance_agg = POS_CASH_balance.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    POS_CASH_balance_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in POS_CASH_balance_agg.columns.tolist()])\n",
    "    POS_CASH_balance_agg['POS_COUNT'] = POS_CASH_balance.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    df = df.merge(POS_CASH_balance_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del current_POS_status\n",
    "    del prev_POS_completed\n",
    "    del prev_POS_active\n",
    "    del POS_CASH_balance\n",
    "    del POS_CASH_balance_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_app(df):\n",
    "\n",
    "    previous_application = pd.read_csv('../data/previous_application.csv')\n",
    "\n",
    "    previous_application['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['APP_CREDIT_PERC'] = previous_application['AMT_APPLICATION'] / previous_application['AMT_CREDIT']\n",
    "    \n",
    "    previous_application, cat_cols = one_hot_encoder(previous_application)\n",
    "    \n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "\n",
    "    prev_agg = previous_application.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "    approved = previous_application[previous_application['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    cols = approved_agg.columns.tolist()\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    refused = previous_application[previous_application['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    for e in cols:\n",
    "        prev_agg['NEW_RATIO_PREV_' + e[0] + \"_\" + e[1].upper()] = prev_agg['APPROVED_' + e[0] + \"_\" + e[1].upper()] / prev_agg['REFUSED_' + e[0] + \"_\" + e[1].upper()]\n",
    "    \n",
    "\n",
    "    df = df.merge(prev_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del previous_application\n",
    "    del prev_agg\n",
    "    del approved\n",
    "    del approved_agg\n",
    "    del refused\n",
    "    del refused_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df):\n",
    "    \n",
    "    # Remove all features that weren't split on above some threshold times in most recent run\n",
    "    importance = pd.read_csv('../output/importance.csv')\n",
    "    importance_threshold = 2\n",
    "    importance_red = importance[importance['importance']<=importance_threshold]\n",
    "    importance_red.reset_index(inplace = True)\n",
    "    importance_list = list(importance_red['feature'])\n",
    "    df = df.drop(importance_list, axis = 1)\n",
    "    \n",
    "    del importance\n",
    "    del importance_red\n",
    "    del importance_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (356255, 149)\n",
      "Process application_train and _test: - done in 17s\n",
      "df shape: (356255, 380)\n",
      "Process bureau and bureau_balance - done in 51s\n",
      "df shape: (356255, 483)\n",
      "Process credit card balance - done in 27s\n",
      "df shape: (356255, 525)\n",
      "Process installments payments - done in 42s\n",
      "df shape: (356255, 541)\n",
      "Process POS_CASH_balance - done in 26s\n",
      "df shape: (356255, 820)\n",
      "Process previous_applications - done in 46s\n",
      "df shape: (356255, 660)\n",
      "Post-processing - done in 5s\n",
      "Processing pipeline run - done in 374s\n"
     ]
    }
   ],
   "source": [
    "def main(importance_prune = False):\n",
    "    with timer(\"Process application_train and _test:\"):\n",
    "        df = application_train_and_test()\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        df = bureau_and_balance(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        df = cc_balance(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process installments payments\"):\n",
    "        df = installments(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process POS_CASH_balance\"):\n",
    "        df = pos_cash(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        df = prev_app(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    if importance_prune == True:\n",
    "        with timer(\"Post-processing\"):\n",
    "            df = remove_features(df)\n",
    "            print(\"df shape:\", df.shape)\n",
    "        \n",
    "    # Save processed data to csv    \n",
    "    df.to_csv('../data/processed_data_3.2.csv')\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with timer(\"Processing pipeline run\"):\n",
    "        main(importance_prune = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
